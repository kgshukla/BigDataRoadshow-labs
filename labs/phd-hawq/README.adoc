== PHD/HAWQ overview lab

This lab will go through a general overview of using PHD and HAWQ. +
For lab and demo purposes, we'll be using a single node Hadoop and HAWQ installation, these will scale horizontally as needed.

Requirements

- PHD+HAWQ SingleNode installation ( available at network.pivotal.io )

=== Starting PHD & HAWQ

If you have already completed SpringXD lab, then your PHD/HawQ is already running. Otherwise go to SpringXD lab and see the section on starting up PHD via Ambari. Proceed to next section.

If you want to look at the status of PHD/HAWQ in Ambari, then login at http://IPADDRESS:8080  (user/passwd is admin/admin)

=== Accessing Hadoop (HDFS)

open a terminal and login using gpadmin/changeme credentials
$ssh gpadmin@<EC2 IPADDRESS>

from the command line run

$hdfs dfs -ls /

$hdfs dfs -mkdir /user/sample

=== Loading data into HDFS

$mkdir -p /home/gpadmin/Desktop/BigDataRoadshow-labs/labs/phd-hawq

$cd /home/gpadmin/Desktop/BigDataRoadshow-labs/labs/phd-hawq

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/1_create_ext_table.sql

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/2_create_hawq_table.sql

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/3_load_hawq_table.sql

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/4_rpm_bands.sql

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/pre_clean.sh

$wget --no-check-certificate  https://raw.githubusercontent.com/kgshukla/BigDataRoadshow-labs/master/labs/phd-hawq/sample.csv

$ls -l

you should see total of 6 files.

now put a copy of the file into HDFS

$hdfs dfs -put sample.csv /user/sample/

check to see if the data was loaded

$hdfs dfs -ls /user/sample

$hdfs dfs -tail /user/sample/sample.csv

=== Using HAWQ

Looks at the structure in HDFS for HAWQ

$hdfs dfs -ls -R /hawq_data

==== Create external table

Create and external table definition that points through to the csv data in HDFS

----
$cd /home/gpadmin/Desktop/BigDataRoadshow-labs/labs/phd-hawq/
$psql -f 1_create_ext_table.sql
----

Things to notice about this create statement

----
CREATE EXTERNAL TABLE stage.car_sample_data_ext (
----

An external table creates the definition of a table for which data will be brought in from an outside source to populate. This data is requested from the source at run time, each time a query is executed against that external table.

----
LOCATION ('pxf://localhost:50070/user/sample/sample.csv?profile=HdfsTextSimple')
FORMAT 'CSV' (HEADER)
LOG ERRORS INTO stage.sample_err SEGMENT REJECT LIMIT 10;
----

The LOCATION clause tell the external table where to go get the data from. In the case the PXF process which reaches out to HDFS for the file requested. This is also a CSV file with a header row. The LOG ERRORS INTO clause puts any errors created by tuples that do not match the table definition into a table. SEGMENT REJECT LIMIT allows for any one HAWQ segment process to run into 10 errors before the query decides the data source is bad and aborts.

==== Create internal table

Create a table internal to HAWQ so we can pull the data directly into HAWQ for faster access

----
$psql -f 2_create_hawq_table.sql
----

==== Load HAWQ Table

Load the data from the external table into the internal table

----
$psql -f 3_load_hawq_table.sql
----

==== Execute queries against table

Execute a query against the external table as well as against the internal table

----
$psql -f 4_rpm_bands.sql
----

==== Pivoral Hadoop Administration, Configuration and Management

Pivotal Hadoop is monitored and managed by Ambari. Ambari is used to install services like Pivotal Hadoop, Zookeeper, Yarn, HAWQ, Hive, HBase, Knox, Ranger etc from a single console. In this section, you would learn how to use Ambari UI and perform few task as mentioned below.

1. administration, configuration management
2. service addition (like HBASE, Zookeeper) via UI.

Follow this link:phd_administration.pdf[link] for the lab

